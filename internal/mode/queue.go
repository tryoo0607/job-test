func RunQueue(ctx context.Context, cfg config.Config) error {
	fmt.Println("ðŸš€ [Queue] RunQueue ì‹œìž‘")
	fmt.Printf("ðŸ”§ [Queue] Redis URL: %s, Queue Key: %s\n", cfg.QueueURL, cfg.QueueKey)
	fmt.Printf("ðŸ”§ [Queue] MaxConcurrency: %d, RetryMax: %d, RetryBackoff: %s\n", cfg.MaxConcurrency, cfg.RetryMax, cfg.RetryBackoff)

	rdb := redis.NewClient(&redis.Options{
		Addr: mustParseRedis(cfg.QueueURL),
	})
	defer rdb.Close()

	p := processor.UppercaseFile{OutDir: cfg.OutputDir}
	fmt.Printf("ðŸ“¤ [Queue] Processor ì¶œë ¥ ë””ë ‰í† ë¦¬: %s\n", cfg.OutputDir)

	g, ctx := errgroup.WithContext(ctx)

	for i := 0; i < cfg.MaxConcurrency; i++ {
		workerID := i
		fmt.Printf("ðŸ‘· [Queue] ì›Œì»¤ #%d ì‹œìž‘\n", workerID)

		g.Go(func() error {
			for {
				select {
				case <-ctx.Done():
					fmt.Printf("ðŸ›‘ [Worker-%d] ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œë¨\n", workerID)
					return ctx.Err()
				default:
				}

				// íì—ì„œ í•­ëª© í•˜ë‚˜ êº¼ë‚´ê¸° (blocking pop)
				res, err := rdb.BRPop(ctx, 5*time.Second, cfg.QueueKey).Result()
				if err == redis.Nil {
					fmt.Printf("âŒ› [Worker-%d] ëŒ€ê¸° ì¤‘... (í ë¹„ì–´ìžˆìŒ)\n", workerID)
					continue
				}
				if err != nil {
					fmt.Printf("âŒ [Worker-%d] Redis pop ì—ëŸ¬: %v\n", workerID, err)
					return fmt.Errorf("redis pop error: %w", err)
				}

				payload := res[1] // res[0]ì€ queue key
				it := processor.Item{
					ID:   generateID(payload),
					Path: payload,
				}

				fmt.Printf("ðŸ“¥ [Worker-%d] ì²˜ë¦¬í•  í•­ëª© ìˆ˜ì‹ : ID=%s, Path=%s\n", workerID, it.ID, it.Path)

				err = runtime.WithRetry(ctx, cfg.RetryMax, cfg.RetryBackoff, func() error {
					fmt.Printf("âš™ï¸  [Worker-%d] Processor ì‹¤í–‰ ì‹œìž‘ (ID=%s)\n", workerID, it.ID)
					return p.Process(ctx, it)
				})

				if err != nil {
					fmt.Printf("âŒ [Worker-%d] ì²˜ë¦¬ ì‹¤íŒ¨ (ID=%s): %v\n", workerID, it.ID, err)
					// TODO: DLQ ì „ì†¡ ë˜ëŠ” ìž¬íìž‰ ë“± ì •ì±…
				} else {
					fmt.Printf("âœ… [Worker-%d] ì²˜ë¦¬ ì„±ê³µ (ID=%s)\n", workerID, it.ID)
				}
			}
		})
	}

	return g.Wait()
}
